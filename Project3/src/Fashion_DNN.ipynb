{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import gc\n",
    "#from talos.model.layers import hidden_layers\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LocallyConnected1D, Conv2D, Reshape, Dropout, MaxPool2D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, History, EarlyStopping\n",
    "from keras.activations import relu, elu, linear\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [10.0, 4.0]\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "mpl.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../data/X_train.npy\")\n",
    "X_test = np.load(\"../data/X_test.npy\")\n",
    "X_val = np.load(\"../data/X_val.npy\")\n",
    "Y_train = np.load(\"../data/Y_train.npy\")\n",
    "Y_test = np.load(\"../data/Y_test.npy\")\n",
    "Y_val = np.load(\"../data/Y_val.npy\")\n",
    "Y_onehot_train = np_utils.to_categorical(Y_train)\n",
    "Y_onehot_test = np_utils.to_categorical(Y_test)\n",
    "Y_onehot_val = np_utils.to_categorical(Y_val)\n",
    "\n",
    "nr_params = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating general model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dense_model(params):\n",
    "    opti = optimizers.Adam(amsgrad=True, lr=params[\"lr\"])\n",
    "    def nn_clf():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(params[\"nr_neurons\"], activation =\"relu\", input_shape = (nr_params,)))\n",
    "        for i in range(1, params[\"nr_layers\"]):\n",
    "            model.add(Dense(params[\"nr_neurons\"]//(i**2), activation =\"relu\"))\n",
    "        model.add(Dense(10, activation = \"softmax\"))\n",
    "        model.compile(optimizer=opti, loss=\"categorical_crossentropy\",  metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    return nn_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\" : 1024,\n",
    "    \"lr\" : 1e-3,\n",
    "    \"nr_neurons\" : 1024,\n",
    "    \"nr_layers\" : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=10, verbose=1, restore_best_weights=True)]\n",
    "clf = KerasClassifier(build_fn=make_dense_model(params), batch_size=params[\"batch_size\"], epochs=100, validation_data=(X_test, Y_onehot_test), callbacks=callbacks, verbose=1)\n",
    "history = clf.fit(X_train, Y_onehot_train)\n",
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(history.history[\"val_accuracy\"], c=\"crimson\")\n",
    "plt.plot(history.history[\"accuracy\"], c=\"navy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "### Learning Rate vs Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = {\n",
    "    \"batch_size\" : [8, 64, 512, 4096],\n",
    "    \"lr\" : [1e-2, 1e-3, 1e-4]\n",
    "}\n",
    "nr_runs = len(all_params['batch_size'])*len(all_params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    \"acc_score\" : [],\n",
    "    \"batch_size\" : [],\n",
    "    \"lr\" : []\n",
    "}\n",
    "\n",
    "k = 0\n",
    "t0 = time.time()\n",
    "for batch_size in all_params[\"batch_size\"]:\n",
    "    for lr in all_params[\"lr\"]:\n",
    "        params = {\n",
    "            \"batch_size\" : batch_size,\n",
    "            \"lr\" : lr,\n",
    "            \"nr_layers\" : 5,\n",
    "            \"nr_neurons\" : 1048\n",
    "             }\n",
    "\n",
    "        hp_dict[\"batch_size\"].append(batch_size)\n",
    "        hp_dict[\"lr\"].append(lr)\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=10, verbose=1, restore_best_weights=True)]\n",
    "        model = make_dense_model(params)\n",
    "        clf = KerasClassifier(build_fn=model, batch_size=params[\"batch_size\"], epochs=200, validation_data=(X_test, Y_onehot_test), callbacks=callbacks, verbose=0)\n",
    "        history = clf.fit(X_train, Y_onehot_train)\n",
    "        Y_pred = clf.predict(X_val)\n",
    "        del history, clf, model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        hp_dict[\"acc_score\"].append(accuracy_score(Y_val, Y_pred))\n",
    "\n",
    "        k += 1\n",
    "        print(f\"{100*k/nr_runs:.1f} %, {(time.time()-t0)/60:.1f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = pd.DataFrame.from_dict(hp_dict)\n",
    "hp_df.to_pickle(\"../data/hp_df_DNN_lr_batch.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = {\n",
    "    \"nr_layers\" : [1, 2, 4, 6, 10],\n",
    "    \"nr_neurons\" : [256, 512, 1024, 2048, 4096]\n",
    "}\n",
    "nr_runs = len(all_params['nr_layers'])*len(all_params[\"nr_neurons\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    \"acc_score\" : [],\n",
    "    \"nr_layers\" : [],\n",
    "    \"nr_neurons\" : []\n",
    "}\n",
    "\n",
    "k = 0\n",
    "t0 = time.time()\n",
    "for nr_layers in all_params[\"nr_layers\"]:\n",
    "    for nr_neurons in all_params[\"nr_neurons\"]:\n",
    "        params = {\n",
    "            \"batch_size\" : 10000,\n",
    "            \"lr\" : 0.01,\n",
    "            \"nr_layers\" : nr_layers,\n",
    "            \"nr_neurons\" : nr_neurons\n",
    "             }\n",
    "\n",
    "        hp_dict[\"nr_layers\"].append(nr_layers)\n",
    "        hp_dict[\"nr_neurons\"].append(nr_neurons)\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=10, verbose=1, restore_best_weights=True)]\n",
    "        model = make_dense_model(params)\n",
    "        clf = KerasClassifier(build_fn=model, batch_size=params[\"batch_size\"], epochs=1, validation_data=(X_test, Y_onehot_test), callbacks=callbacks, verbose=0)\n",
    "        history = clf.fit(X_train, Y_onehot_train)\n",
    "        Y_pred = clf.predict(X_val)\n",
    "        del history, clf, model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        hp_dict[\"acc_score\"].append(accuracy_score(Y_val, Y_pred))\n",
    "\n",
    "        k += 1\n",
    "        print(f\"{100*k/nr_runs:.1f} %, {(time.time()-t0)/60:.1f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = pd.DataFrame.from_dict(hp_dict)\n",
    "hp_df.to_pickle(\"../data/hp_df_DNN_network_size.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
