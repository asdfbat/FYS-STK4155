{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import gc\n",
    "#from talos.model.layers import hidden_layers\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LocallyConnected1D, Conv1D, Reshape\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras.activations import relu, elu, linear\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [10.0, 4.0]\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "mpl.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Neural Network on WHR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_pickle(\"../data/world_happiness.pickle\")\n",
    "data = data_pd.to_numpy()[:,2:]; data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data[:,1:]\n",
    "output_data = data[:,0]\n",
    "nr_params = input_data.shape[1]; nr_datapoints = input_data.shape[0]; nr_params, nr_datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(Y_test, Y_pred):\n",
    "    return np.sum(Y_test == Y_pred) / len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = {\n",
    "    \"hidden_layers\" : [1, 2, 4],\n",
    "    \"neurons\" : [4, 8, 16],\n",
    "    \"epochs\" : [100, 200, 400, 800],\n",
    "    \"lr\" : [0.01, 0.001, 0.0001]\n",
    "}\n",
    "nr_runs = np.prod([len(nr) for nr in all_params.values()])\n",
    "nr_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(params):\n",
    "    opti = optimizers.Adam(amsgrad=True, lr=params[\"lr\"])\n",
    "    def nn_reg():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(params[\"neurons\"], input_shape=(nr_params,), activation=\"linear\", kernel_initializer='random_uniform'))\n",
    "        for i in range(params[\"hidden_layers\"] - 1):\n",
    "            model.add(Dense(params[\"neurons\"], activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "        model.add(Dense(1, activation=\"linear\", kernel_initializer='random_uniform'))\n",
    "        model.compile(optimizer=opti, loss=\"mean_squared_error\",  metrics=[\"mse\"])\n",
    "        return model\n",
    "    return nn_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    \"r2_score\" : [],\n",
    "    \"r2_std\" : [],\n",
    "    \"hidden_layers\" : [],\n",
    "    \"neurons\" : [],\n",
    "    \"lr\" : [],\n",
    "    \"epochs\" : []\n",
    "}\n",
    "\n",
    "nr_averages = 40\n",
    "\n",
    "k = 0\n",
    "t0 = time.time()\n",
    "for hidden_layers in all_params[\"hidden_layers\"]:\n",
    "    for neurons in all_params[\"neurons\"]:\n",
    "        for epochs in all_params[\"epochs\"]:\n",
    "            for lr in all_params[\"lr\"]:\n",
    "                params = {\n",
    "                    \"hidden_layers\" : hidden_layers,\n",
    "                    \"neurons\" : neurons,\n",
    "                    \"epochs\" : epochs,\n",
    "                    \"lr\" : lr\n",
    "                         }\n",
    "\n",
    "                hp_dict[\"hidden_layers\"].append(hidden_layers)\n",
    "                hp_dict[\"neurons\"].append(neurons)\n",
    "                hp_dict[\"epochs\"].append(epochs)\n",
    "                hp_dict[\"lr\"].append(lr)\n",
    "\n",
    "                r2 = 0\n",
    "                r22 = 0\n",
    "                for i in range(nr_averages):\n",
    "                    X_train, X_test, Y_train, Y_test = train_test_split(input_data, output_data, test_size=0.1)\n",
    "                    model = make_model(params)\n",
    "                    reg = KerasRegressor(build_fn=make_model(params), batch_size=32, epochs=epochs, validation_split=0, verbose=0)\n",
    "                    history = reg.fit(X_train, Y_train)\n",
    "                    Y_pred = reg.predict(X_test)\n",
    "                    r2 += r2_score(Y_test, Y_pred)\n",
    "                    r22 += r2_score(Y_test, Y_pred)**2\n",
    "                    #plt.plot(history.history[\"mse\"])\n",
    "                    del history, reg, model\n",
    "                    gc.collect()\n",
    "                    K.clear_session()\n",
    "                hp_dict[\"r2_score\"].append(r2/nr_averages)\n",
    "                hp_dict[\"r2_std\"].append(r22/nr_averages)  # Placeholder for std. Atm just <r2^2>.\n",
    "\n",
    "                k += 1\n",
    "                print(f\"{100*k/nr_runs:.1f} %, {(time.time()-t0)/60:.1f} m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = pd.DataFrame(hp_dict).sort_values(by=\"r2_score\", ascending=False);\n",
    "hp_df[\"r2_std\"] = np.sqrt(hp_df[\"r2_std\"] - hp_df[\"r2_score\"]**2); hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.to_pickle(\"../data/WHR_hyperparam.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "asdf = [hp_df[hp_df[\"neurons\"] == i][\"r2_score\"] for i in [2, 4, 8]]\n",
    "ax[0].boxplot(asdf);\n",
    "ax[0].set_xlabel(\"Neurons per layer\")\n",
    "ax[0].set_ylabel(\"R2 Score\")\n",
    "ax[0].set_xticks([1,2,3], [\"4\", \"8\", \"16\"]);\n",
    "asdf = [hp_df[hp_df[\"hidden_layers\"] == i][\"r2_score\"] for i in [1, 2, 4]]\n",
    "ax[1].boxplot(asdf);\n",
    "ax[1].set_xlabel(\"Nr of Layers\")\n",
    "ax[1].set_xticks([1,2,3], [\"1\", \"2\", \"4\"]);\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figs/WHR_TF_boxplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.0001, 0.001, 0.003]\n",
    "epochs = [100, 200, 400, 800]\n",
    "asdf = np.zeros((3,4))\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        asdf[i,j] = np.mean(hp_df[(hp_df[\"epochs\"]==epochs[j]) & (hp_df[\"lr\"]==lrs[i])][\"r2_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(asdf, annot=True, xticklabels=epochs, yticklabels=lrs, vmin=0.7, vmax=0.8, cmap=\"Purples\", square=True)\n",
    "plt.ylim(0, 3)\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"../figs/CC_TF_lr_epoch_heatmap\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casual NN fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optimizers.Adam(amsgrad=True, lr=0.0001)\n",
    "def nn_reg():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, input_shape=(nr_params,), activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    for i in range(4 - 1):\n",
    "        model.add(Dense(2, activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer='random_uniform'))\n",
    "    model.compile(optimizer=opti, loss=\"mean_squared_error\",  metrics=[\"mse\", r2_keras])\n",
    "    return model\n",
    "nn_reg().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_averages = 40\n",
    "r2_NN = np.zeros(1)\n",
    "r22_NN = np.zeros(1)\n",
    "\n",
    "histories = []\n",
    "\n",
    "for i in trange(nr_averages):\n",
    "    reg = KerasRegressor(build_fn=nn_reg, batch_size=32, epochs=100, validation_split=0.1, verbose=0)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(input_data, output_data, test_size=0.1)\n",
    "    Scaler = preprocessing.StandardScaler()\n",
    "    X_train_scaled = Scaler.fit_transform(X_train)\n",
    "    X_test_scaled = Scaler.transform(X_test)\n",
    "    \n",
    "    history = reg.fit(X_train_scaled, Y_train)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nr_averages):\n",
    "    plt.plot(histories[i].history[\"val_r2_keras\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
