{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import gc\n",
    "#from talos.model.layers import hidden_layers\n",
    "from keras import optimizers, regularizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LocallyConnected1D, Conv1D, Reshape\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras.activations import relu, elu, linear\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "\n",
    "from regression_problem import Regression\n",
    "from neural_network import NeuralNetwork\n",
    "from tqdm import trange\n",
    "\n",
    "mpl.rcdefaults()\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [10.0, 4.0]\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "mpl.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = [\"Happiness\", \"Economy\", \"Family\", \"Health\", \"Freedom\", \"Trust\", \"Generosity\"]\n",
    "data_df = pd.read_pickle(\"../data/world_happiness.pickle\")[parameter_names]\n",
    "data = data_df.to_numpy()\n",
    "output = data[:,0].reshape(-1,1)\n",
    "input_data = data[:,1:]\n",
    "nr_params = input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [02:50<25:31, 85.07s/it]"
     ]
    }
   ],
   "source": [
    "timings_self = np.zeros(20)\n",
    "timings_TF = np.zeros(20)\n",
    "nr_neurons_list = np.logspace(1, 3, 20, dtype=int)\n",
    "nr_averages = 10\n",
    "\n",
    "for i in trange(20):\n",
    "    epochs = 1000\n",
    "    nr_neurons = nr_neurons_list[i]\n",
    "    \n",
    "\n",
    "    hidden_neuron_list = [nr_neurons, nr_neurons]\n",
    "    reg = Regression(hidden_activation='RELU')\n",
    "    eta = 1e-3\n",
    "    lmbd = 0\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(input_data, output,test_size=0.3)\n",
    "    Scaler = preprocessing.StandardScaler()\n",
    "    X_train_scaled = Scaler.fit_transform(X_train)\n",
    "    X_test_scaled = Scaler.transform(X_test)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for j in range(nr_averages):\n",
    "        nn = NeuralNetwork( X_train_scaled,\n",
    "                            Y_train,\n",
    "                            problem=reg,\n",
    "                            n_hidden_neurons_list=hidden_neuron_list,\n",
    "                            n_output_neurons=1,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=32,\n",
    "                            eta=eta,\n",
    "                            lmbd=lmbd,\n",
    "                            debug=False)\n",
    "        nn.SGD(track=False)\n",
    "    timings_self[i] = (time.time() - t0)/nr_averages\n",
    "\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(nr_averages):\n",
    "        opti = optimizers.SGD(lr=1e-3)\n",
    "        def nn_reg():\n",
    "            model = Sequential()\n",
    "            model.add(Dense(nr_neurons, input_shape=(nr_params,), activation=\"relu\", kernel_initializer='random_normal'))\n",
    "            model.add(Dense(nr_neurons, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "            model.add(Dense(1, activation=\"linear\", kernel_initializer='random_normal'))\n",
    "            model.compile(optimizer=opti, loss=\"mean_squared_error\")\n",
    "            return model\n",
    "        reg = KerasRegressor(build_fn=nn_reg, batch_size=32, epochs=epochs, validation_data=(X_test_scaled, Y_test), verbose=0)\n",
    "        history = reg.fit(X_train_scaled, Y_train)\n",
    "    timings_TF[i] = (time.time() - t0)/nr_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
